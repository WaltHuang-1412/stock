#!/usr/bin/env python3
"""
å°è‚¡æ™‚äº‹åˆ†æå·¥å…· v3.0
æ•´åˆå¤šä¾†æºå‹•æ…‹ç²å–å°è‚¡è³‡è¨Šï¼š
1. è­‰äº¤æ‰€æ–°è API - å®˜æ–¹å…¬å‘Š
2. è­‰äº¤æ‰€å…¬å‘Š API - é‡å¤§è¨Šæ¯
3. é‰…äº¨ç¶²æ–°è API - è²¡ç¶“æ–°è + é—œéµå­—
4. ç¶“æ¿Ÿæ—¥å ± RSS - è£œå……æ–°è

æ‰€æœ‰è³‡æ–™çš†å¾å³æ™‚ä¾†æºå‹•æ…‹ç²å–ï¼Œç„¡ç¡¬ç·¨ç¢¼

ç”¨æ³•ï¼š
  python3 scripts/fetch_tw_market_news.py
"""

import requests
import sys
from datetime import datetime
from bs4 import BeautifulSoup
import json
import re
import xml.etree.ElementTree as ET

# å¿½ç•¥ SSL è­¦å‘Š
import warnings
warnings.filterwarnings('ignore')

# é‡é»è‚¡ç¥¨åç¨±å°ç…§ï¼ˆç”¨æ–¼æ¨™è¨»ï¼‰
STOCK_NAMES = {
    # åŠå°é«”
    '2330': 'å°ç©é›»', '2303': 'è¯é›»', '2454': 'è¯ç™¼ç§‘', '3711': 'æ—¥æœˆå…‰æŠ•æ§',
    '2379': 'ç‘æ˜±', '3034': 'è¯è© ', '6770': 'åŠ›ç©é›»', '2408': 'å—äºç§‘',
    '2344': 'è¯é‚¦é›»', '2337': 'æ—ºå®',
    # é›»å­
    '2317': 'é´»æµ·', '2382': 'å»£é”', '3231': 'ç·¯å‰µ', '2357': 'è¯ç¢©',
    '3037': 'æ¬£èˆˆ', '3189': 'æ™¯ç¢©', '8046': 'å—é›»', '6239': 'åŠ›æˆ',
    # é‡‘è
    '2881': 'å¯Œé‚¦é‡‘', '2882': 'åœ‹æ³°é‡‘', '2883': 'å‡±åŸºé‡‘', '2884': 'ç‰å±±é‡‘',
    '2885': 'å…ƒå¤§é‡‘', '2886': 'å…†è±é‡‘', '2887': 'å°æ–°é‡‘', '2891': 'ä¸­ä¿¡é‡‘',
    '2890': 'æ°¸è±é‡‘', '2892': 'ç¬¬ä¸€é‡‘',
    # å‚³ç”¢
    '1301': 'å°å¡‘', '1303': 'å—äº', '1326': 'å°åŒ–', '2002': 'ä¸­é‹¼',
    '2603': 'é•·æ¦®', '2609': 'é™½æ˜', '2615': 'è¬æµ·',
    # å…¶ä»–
    '3481': 'ç¾¤å‰µ', '2409': 'å‹é”', '8150': 'å—èŒ‚'
}


def get_twse_news():
    """å¾è­‰äº¤æ‰€ç²å–å®˜æ–¹æ–°è"""
    news = []
    url = 'https://www.twse.com.tw/rwd/zh/news/newsList?limit=15'

    try:
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            data = r.json()
            if data.get('stat') == 'ok' and 'data' in data:
                for item in data['data'][:10]:
                    if len(item) >= 3:
                        news.append({
                            'title': item[1][:80] if len(item) > 1 else '',
                            'date': item[2] if len(item) > 2 else '',
                            'source': 'è­‰äº¤æ‰€',
                            'type': 'official'
                        })
    except Exception as e:
        print(f"  âš ï¸ è­‰äº¤æ‰€æ–°è: {e}")

    return news


def get_twse_announcements():
    """å¾è­‰äº¤æ‰€ç²å–å…¬å‘Š"""
    announcements = []
    url = 'https://www.twse.com.tw/rwd/zh/announcement/announcement?limit=10'

    try:
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            data = r.json()
            if data.get('stat') == 'ok' and 'data' in data:
                for item in data['data'][:8]:
                    if len(item) >= 4:
                        announcements.append({
                            'date': item[1] if len(item) > 1 else '',
                            'doc_no': item[2] if len(item) > 2 else '',
                            'subject': item[3][:100] if len(item) > 3 else '',
                            'source': 'è­‰äº¤æ‰€å…¬å‘Š'
                        })
    except Exception as e:
        print(f"  âš ï¸ è­‰äº¤æ‰€å…¬å‘Š: {e}")

    return announcements


def get_cnyes_news():
    """å¾é‰…äº¨ç¶²ç²å–è²¡ç¶“æ–°è"""
    news = []
    url = 'https://news.cnyes.com/api/v3/news/category/tw_stock'

    try:
        headers = {'User-Agent': 'Mozilla/5.0', 'Accept': 'application/json'}
        params = {'page': 1, 'limit': 20}

        r = requests.get(url, headers=headers, params=params, timeout=10)

        if r.status_code == 200:
            data = r.json()
            if 'items' in data and 'data' in data['items']:
                for item in data['items']['data'][:15]:
                    publish_time = item.get('publishAt', 0)
                    date_str = datetime.fromtimestamp(publish_time).strftime('%Y-%m-%d %H:%M') if publish_time else ''

                    news.append({
                        'title': item.get('title', ''),
                        'date': date_str,
                        'summary': item.get('summary', '')[:100],
                        'keywords': item.get('keyword', []),
                        'source': 'é‰…äº¨ç¶²'
                    })
    except Exception as e:
        print(f"  âš ï¸ é‰…äº¨ç¶²æ–°è: {e}")

    return news


def get_udn_rss():
    """å¾ç¶“æ¿Ÿæ—¥å ± RSS ç²å–æ–°è"""
    news = []
    url = 'https://money.udn.com/rssfeed/news/1001/5590'

    try:
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            root = ET.fromstring(r.content)

            for item in root.findall('.//item')[:10]:
                title = item.find('title')
                pub_date = item.find('pubDate')

                if title is not None:
                    news.append({
                        'title': title.text[:80] if title.text else '',
                        'date': pub_date.text[:25] if pub_date is not None and pub_date.text else '',
                        'source': 'ç¶“æ¿Ÿæ—¥å ±'
                    })
    except Exception as e:
        print(f"  âš ï¸ ç¶“æ¿Ÿæ—¥å ± RSS: {e}")

    return news


def detect_conferences(all_news):
    """å¾æ–°èä¸­åµæ¸¬æ³•èªªæœƒè³‡è¨Š"""
    conferences = []
    conf_keywords = ['æ³•èªª', 'æ³•äººèªªæ˜', 'æ¥­ç¸¾ç™¼è¡¨', 'æ¥­ç¸¾èªªæ˜æœƒ']

    seen = set()
    for news in all_news:
        title = news.get('title', '')

        if any(kw in title for kw in conf_keywords):
            # å˜—è©¦æå–è‚¡ç¥¨åç¨±
            for code, name in STOCK_NAMES.items():
                if name in title and code not in seen:
                    seen.add(code)
                    conferences.append({
                        'stock_code': code,
                        'stock_name': name,
                        'title': title[:60],
                        'date': news.get('date', ''),
                        'source': news.get('source', '')
                    })
                    break

    return conferences


def detect_events(all_news):
    """å¾æ–°èä¸­åµæ¸¬é‡è¦äº‹ä»¶"""
    events = []

    event_keywords = {
        'Fed': ('Fedåˆ©ç‡æ±ºè­°', 'é‡‘èè‚¡', 'âš ï¸ é«˜'),
        'å‡æ¯': ('å¤®è¡Œå‡æ¯', 'é‡‘èè‚¡', 'âš ï¸ é«˜'),
        'é™æ¯': ('å¤®è¡Œé™æ¯', 'é‡‘èè‚¡', 'âš ï¸ é«˜'),
        'CPI': ('CPIå…¬å¸ƒ', 'å…¨å¸‚å ´', 'ğŸ“Œ æ³¨æ„'),
        'éè¾²': ('éè¾²å°±æ¥­æ•¸æ“š', 'å…¨å¸‚å ´', 'ğŸ“Œ æ³¨æ„'),
        'è²¡å ±': ('è²¡å ±å­£', 'å…¨å¸‚å ´', 'ğŸ“Œ æ³¨æ„'),
        'é™¤æ¯': ('é™¤æ¬Šæ¯æ—ºå­£', 'é«˜æ¯è‚¡', 'ğŸ“Œ æ³¨æ„'),
    }

    detected = set()
    for news in all_news:
        title = news.get('title', '') + news.get('summary', '')

        for keyword, (event_name, stocks, impact) in event_keywords.items():
            if keyword in title and event_name not in detected:
                detected.add(event_name)
                events.append({
                    'event': event_name,
                    'stocks': stocks,
                    'impact': impact,
                    'source_title': news.get('title', '')[:40],
                    'date': news.get('date', '')
                })

    return events[:5]


def analyze_hot_topics(all_news):
    """åˆ†æç†±é–€é¡Œæ"""
    keywords = {}

    hot_topics = {
        'AI': ['AI', 'äººå·¥æ™ºæ…§', 'GPU', 'è¼é”', 'NVIDIA', 'ChatGPT', 'Blackwell'],
        'è¨˜æ†¶é«”': ['è¨˜æ†¶é«”', 'DRAM', 'HBM', 'NAND', 'ç¾å…‰', 'Micron'],
        'åŠå°é«”': ['åŠå°é«”', 'æ™¶ç‰‡', 'æ™¶åœ“', 'CoWoS', 'å…ˆé€²å°è£', 'å°ç©é›»'],
        'é¢æ¿': ['é¢æ¿', 'LCD', 'OLED', 'é¡¯ç¤ºå™¨', 'ç¾¤å‰µ', 'å‹é”'],
        'é›»å‹•è»Š': ['é›»å‹•è»Š', 'EV', 'ç‰¹æ–¯æ‹‰', 'é›»æ± ', 'å……é›»'],
        'èˆªé‹': ['èˆªé‹', 'é‹åƒ¹', 'è²¨æ«ƒ', 'BDI', 'é•·æ¦®', 'é™½æ˜'],
        'é‡‘è': ['å‡æ¯', 'é™æ¯', 'Fed', 'å¤®è¡Œ', 'é‡‘è', 'éŠ€è¡Œ', 'å£½éšª'],
        'ä½µè³¼': ['ä½µè³¼', 'æ”¶è³¼', 'åˆä½µ', 'è‚¡æ¬Š'],
        'ETF': ['ETF', 'æˆåˆ†è‚¡', 'èª¿æ•´', 'ç´å…¥'],
    }

    for news in all_news:
        text = news.get('title', '') + news.get('summary', '')
        # ä¹Ÿä½¿ç”¨é‰…äº¨ç¶²æä¾›çš„é—œéµå­—
        if news.get('keywords'):
            text += ' '.join(news.get('keywords', []))

        for topic, kws in hot_topics.items():
            for kw in kws:
                if kw in text:
                    keywords[topic] = keywords.get(topic, 0) + 1
                    break

    return sorted(keywords.items(), key=lambda x: x[1], reverse=True)[:6]


def print_summary(twse_news, twse_announcements, cnyes_news, udn_news, conferences, events, hot_topics):
    """è¼¸å‡ºæ™‚äº‹æ‘˜è¦"""
    today = datetime.now().strftime('%Y-%m-%d')
    weekday = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥'][datetime.now().weekday()]
    time_now = datetime.now().strftime('%H:%M')

    print("\n" + "=" * 60)
    print(f"ğŸ“¢ å°è‚¡æ™‚äº‹æƒæ v3.0ï¼ˆ{today} é€±{weekday} {time_now}ï¼‰")
    print("=" * 60)

    # ç†±é–€é¡Œæ
    print("\nã€ğŸ”¥ ç†±é–€é¡Œæã€‘")
    if hot_topics:
        for topic, count in hot_topics:
            bar = "â–ˆ" * min(count, 10)
            print(f"  â€¢ {topic}: {bar} ({count}å‰‡)")
    else:
        print("  ï¼ˆåˆ†æä¸­...ï¼‰")

    # åµæ¸¬åˆ°çš„é‡è¦äº‹ä»¶
    print("\nã€â° åµæ¸¬åˆ°çš„äº‹ä»¶ã€‘")
    if events:
        for e in events:
            print(f"  {e['impact']} {e['event']} - å½±éŸ¿ï¼š{e['stocks']}")
            print(f"      ä¾†æºï¼š{e['source_title']}...")
    else:
        print("  ï¼ˆä»Šæ—¥æ–°èæœªåµæ¸¬åˆ°é‡å¤§äº‹ä»¶ï¼‰")

    # åµæ¸¬åˆ°çš„æ³•èªªæœƒ
    print("\nã€ğŸ“… åµæ¸¬åˆ°çš„æ³•èªªæœƒã€‘")
    if conferences:
        for c in conferences:
            print(f"  â­ {c['stock_name']}({c['stock_code']})")
            print(f"      {c['title'][:50]}...")
    else:
        print("  ï¼ˆä»Šæ—¥æ–°èæœªæåŠæ³•èªªæœƒï¼‰")

    # è­‰äº¤æ‰€å®˜æ–¹å…¬å‘Š
    print("\nã€ğŸ“£ è­‰äº¤æ‰€å…¬å‘Šã€‘")
    if twse_announcements:
        for a in twse_announcements[:5]:
            print(f"  â€¢ {a['subject'][:55]}...")
    else:
        print("  ï¼ˆç„¡æœ€æ–°å…¬å‘Šï¼‰")

    # è­‰äº¤æ‰€æ–°è
    print("\nã€ğŸ“° è­‰äº¤æ‰€æ–°èã€‘")
    if twse_news:
        for n in twse_news[:5]:
            print(f"  â€¢ {n['title'][:55]}...")
    else:
        print("  ï¼ˆç„¡æœ€æ–°æ–°èï¼‰")

    # è²¡ç¶“æ–°èï¼ˆé‰…äº¨ç¶² + ç¶“æ¿Ÿæ—¥å ±ï¼‰
    print("\nã€ğŸ“° è²¡ç¶“æ–°èã€‘")
    all_financial_news = cnyes_news + udn_news
    if all_financial_news:
        seen = set()
        count = 0
        for n in all_financial_news:
            title = n.get('title', '')[:50]
            if title and title not in seen and count < 10:
                seen.add(title)
                source = n.get('source', '')
                print(f"  [{source}] {title}...")
                count += 1
    else:
        print("  ï¼ˆè¼‰å…¥ä¸­...ï¼‰")

    print("\n" + "=" * 60)
    print("âœ… æƒæå®Œæˆï¼ˆè³‡æ–™ä¾†æºï¼šè­‰äº¤æ‰€ã€é‰…äº¨ç¶²ã€ç¶“æ¿Ÿæ—¥å ±ï¼‰")
    print("=" * 60)

    return {
        'date': today,
        'hot_topics': hot_topics,
        'events': events,
        'conferences': conferences,
        'announcements': twse_announcements,
        'twse_news': twse_news,
        'news': cnyes_news[:10]
    }


def main():
    print("â³ æ­£åœ¨æƒæå°è‚¡æ™‚äº‹...")

    # æŸ¥è©¢å„ä¾†æº
    print("ğŸ“¡ æŸ¥è©¢è­‰äº¤æ‰€æ–°è...")
    twse_news = get_twse_news()
    print(f"   æ‰¾åˆ° {len(twse_news)} å‰‡")

    print("ğŸ“¡ æŸ¥è©¢è­‰äº¤æ‰€å…¬å‘Š...")
    twse_announcements = get_twse_announcements()
    print(f"   æ‰¾åˆ° {len(twse_announcements)} å‰‡")

    print("ğŸ“¡ æŸ¥è©¢é‰…äº¨ç¶²æ–°è...")
    cnyes_news = get_cnyes_news()
    print(f"   æ‰¾åˆ° {len(cnyes_news)} å‰‡")

    print("ğŸ“¡ æŸ¥è©¢ç¶“æ¿Ÿæ—¥å ±...")
    udn_news = get_udn_rss()
    print(f"   æ‰¾åˆ° {len(udn_news)} å‰‡")

    # æ•´åˆæ‰€æœ‰æ–°èé€²è¡Œåˆ†æ
    all_news = twse_news + cnyes_news + udn_news

    print("ğŸ“¡ åˆ†æç†±é–€é¡Œæ...")
    hot_topics = analyze_hot_topics(all_news)

    print("ğŸ“¡ åµæ¸¬æ³•èªªæœƒ...")
    conferences = detect_conferences(all_news)
    print(f"   åµæ¸¬åˆ° {len(conferences)} å ´")

    print("ğŸ“¡ åµæ¸¬é‡è¦äº‹ä»¶...")
    events = detect_events(all_news)
    print(f"   åµæ¸¬åˆ° {len(events)} å€‹")

    # è¼¸å‡ºæ‘˜è¦
    result = print_summary(twse_news, twse_announcements, cnyes_news, udn_news,
                          conferences, events, hot_topics)

    # å„²å­˜çµæœ
    today = datetime.now().strftime('%Y-%m-%d')
    output_dir = f'data/{today}'

    try:
        import os
        os.makedirs(output_dir, exist_ok=True)

        output_file = f'{output_dir}/tw_market_news.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ’¾ å·²å„²å­˜è‡³ {output_file}")
    except Exception as e:
        print(f"\nâš ï¸ å„²å­˜å¤±æ•—: {e}")


if __name__ == '__main__':
    main()
