#!/usr/bin/env python3
"""
æ™‚äº‹è­˜åˆ¥å¼•æ“ - è‡ªå‹•è­˜åˆ¥ä»Šæ—¥ç†±é»ç”¢æ¥­
è¼¸å…¥ï¼šç¾è‚¡æ•¸æ“š + å°è‚¡æ–°è
è¼¸å‡ºï¼šç†±é»ç”¢æ¥­æ¸…å–® + å‚¬åŒ–å¼·åº¦
"""

import json
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def load_industry_chains():
    """è¼‰å…¥ç”¢æ¥­éˆçŸ¥è­˜åº«"""
    chains_file = project_root / "data" / "industry_chains.json"
    with open(chains_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def load_us_asia_markets(date_str):
    """è¼‰å…¥ç¾è‚¡/äºè‚¡æ•¸æ“š"""
    market_file = project_root / "data" / date_str / "us_asia_markets.json"
    try:
        with open(market_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ° {market_file}ï¼Œè¿”å›ç©ºæ•¸æ“š", file=sys.stderr)
        return {}


def load_tw_news(date_str):
    """è¼‰å…¥å°è‚¡æ–°è"""
    news_file = project_root / "data" / date_str / "tw_market_news.json"
    try:
        # å˜—è©¦å¤šç¨®ç·¨ç¢¼
        for encoding in ['utf-8', 'utf-8-sig', 'cp950', 'gbk']:
            try:
                with open(news_file, 'r', encoding=encoding) as f:
                    data = json.load(f)
                    return data
            except (UnicodeDecodeError, json.JSONDecodeError):
                continue

        # å¦‚æœæ‰€æœ‰ç·¨ç¢¼éƒ½å¤±æ•—ï¼Œè¿”å›ç©ºæ•¸æ“š
        print(f"è­¦å‘Šï¼šç„¡æ³•è§£æ {news_file}ï¼Œè¿”å›ç©ºæ•¸æ“š", file=sys.stderr)
        return []
    except FileNotFoundError:
        print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ° {news_file}ï¼Œè¿”å›ç©ºæ•¸æ“š", file=sys.stderr)
        return []


def identify_from_us_markets(markets_data, industry_chains):
    """å¾ç¾è‚¡æ•¸æ“šè­˜åˆ¥ç†±é»"""
    hotspots = []

    # æª¢æŸ¥è¼é”/AMDï¼ˆAIç”¢æ¥­ï¼‰
    nvidia_change = markets_data.get("NVIDIA", 0)
    amd_change = markets_data.get("AMD", 0)
    ai_change = max(nvidia_change, amd_change)

    if ai_change > 3:
        hotspots.append({
            "industry": "AI",
            "catalyst": f"è¼é”{nvidia_change:+.2f}%" if nvidia_change > amd_change else f"AMD{amd_change:+.2f}%",
            "strength": "strong" if ai_change > 5 else "medium",
            "change": ai_change
        })

    # æª¢æŸ¥è²»åŠï¼ˆåŠå°é«”ç”¢æ¥­ï¼‰
    sox_change = markets_data.get("è²»åŸåŠå°é«”", 0)
    if sox_change > 1:
        hotspots.append({
            "industry": "åŠå°é«”",
            "catalyst": f"è²»åŠ{sox_change:+.2f}%",
            "strength": "strong" if sox_change > 2 else "medium",
            "change": sox_change
        })

    # æª¢æŸ¥æ²¹åƒ¹ï¼ˆå¡‘åŒ–/èˆªç©ºç”¢æ¥­ï¼‰
    oil_change = markets_data.get("WTIåŸæ²¹", 0)
    if abs(oil_change) > 2:
        if oil_change > 0:
            hotspots.append({
                "industry": "å¡‘åŒ–",
                "catalyst": f"æ²¹åƒ¹{oil_change:+.2f}%",
                "strength": "strong" if oil_change > 5 else "medium",
                "change": oil_change
            })
        else:
            hotspots.append({
                "industry": "èˆªç©º",
                "catalyst": f"æ²¹åƒ¹{oil_change:+.2f}%ï¼ˆåˆ©å¤šèˆªç©ºï¼‰",
                "strength": "medium" if oil_change < -3 else "weak",
                "change": abs(oil_change)
            })

    # æª¢æŸ¥Micronï¼ˆè¨˜æ†¶é«”ç”¢æ¥­ï¼‰
    micron_change = markets_data.get("Micron", 0)
    if micron_change > 3:
        hotspots.append({
            "industry": "è¨˜æ†¶é«”",
            "catalyst": f"Micron{micron_change:+.2f}%",
            "strength": "strong" if micron_change > 5 else "medium",
            "change": micron_change
        })

    return hotspots


def identify_from_tw_news(news_data, industry_chains):
    """å¾å°è‚¡æ–°èè­˜åˆ¥ç†±é»"""
    hotspots = []

    if not news_data:
        return hotspots

    # éæ­·æ‰€æœ‰ç”¢æ¥­ï¼Œæª¢æŸ¥æ–°èé—œéµå­—
    for industry_key, industry_info in industry_chains["industries"].items():
        catalysts = industry_info.get("catalysts", [])

        # æª¢æŸ¥æ–°èä¸­æ˜¯å¦åŒ…å«ç”¢æ¥­é—œéµå­—
        matched_news = []
        for news_item in news_data:
            if isinstance(news_item, dict):
                title = news_item.get("title", "")
                content = news_item.get("content", "")
            else:
                title = str(news_item)
                content = ""

            # æª¢æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•å‚¬åŒ–åŠ‘é—œéµå­—
            for catalyst in catalysts:
                if catalyst in title or catalyst in content:
                    matched_news.append(title)
                    break

        # å¦‚æœæœ‰åŒ¹é…çš„æ–°èï¼ŒåŠ å…¥ç†±é»
        if matched_news:
            # æ ¹æ“šæ–°èæ•¸é‡åˆ¤æ–·å¼·åº¦
            if len(matched_news) >= 3:
                strength = "strong"
            elif len(matched_news) >= 2:
                strength = "medium"
            else:
                strength = "weak"

            hotspots.append({
                "industry": industry_key,
                "catalyst": f"{industry_info['name']}ç›¸é—œæ–°è Ã— {len(matched_news)}",
                "strength": strength,
                "news": matched_news[:2]  # åªä¿ç•™å‰2æ¢æ–°è
            })

    return hotspots


def merge_and_deduplicate(us_hotspots, tw_hotspots):
    """åˆä½µä¸¦å»é‡ç†±é»"""
    merged = {}

    # å…ˆåŠ å…¥ç¾è‚¡ç†±é»ï¼ˆå„ªå…ˆï¼‰
    for hotspot in us_hotspots:
        industry = hotspot["industry"]
        merged[industry] = hotspot

    # åŠ å…¥å°è‚¡æ–°èç†±é»
    for hotspot in tw_hotspots:
        industry = hotspot["industry"]
        if industry in merged:
            # å·²å­˜åœ¨ï¼šæå‡å¼·åº¦
            if hotspot["strength"] == "strong":
                merged[industry]["strength"] = "strong"
            merged[industry]["catalyst"] += f" + {hotspot['catalyst']}"
        else:
            # æ–°ç”¢æ¥­
            merged[industry] = hotspot

    # è½‰å›åˆ—è¡¨ä¸¦æ’åºï¼ˆstrong > medium > weakï¼‰
    strength_order = {"strong": 3, "medium": 2, "weak": 1}
    result = sorted(
        merged.values(),
        key=lambda x: strength_order[x["strength"]],
        reverse=True
    )

    return result


def main():
    """ä¸»å‡½æ•¸"""
    # ç²å–æ—¥æœŸåƒæ•¸
    if len(sys.argv) > 1:
        date_str = sys.argv[1]
    else:
        date_str = datetime.now().strftime("%Y-%m-%d")

    print(f"ğŸ” æ™‚äº‹è­˜åˆ¥å¼•æ“ - {date_str}")
    print("=" * 60)

    # è¼‰å…¥æ•¸æ“š
    print("\nğŸ“¥ è¼‰å…¥æ•¸æ“š...")
    industry_chains = load_industry_chains()
    us_markets = load_us_asia_markets(date_str)
    tw_news = load_tw_news(date_str)

    print(f"  âœ“ ç”¢æ¥­éˆçŸ¥è­˜åº«ï¼š{len(industry_chains['industries'])} å€‹ç”¢æ¥­")
    print(f"  âœ“ ç¾è‚¡æ•¸æ“šï¼š{len(us_markets)} å€‹æŒ‡æ¨™")
    print(f"  âœ“ å°è‚¡æ–°èï¼š{len(tw_news) if tw_news else 0} å‰‡")

    # è­˜åˆ¥ç†±é»
    print("\nğŸ¯ è­˜åˆ¥ç†±é»ç”¢æ¥­...")
    us_hotspots = identify_from_us_markets(us_markets, industry_chains)
    tw_hotspots = identify_from_tw_news(tw_news, industry_chains)

    print(f"  âœ“ ç¾è‚¡è§¸ç™¼ï¼š{len(us_hotspots)} å€‹ç”¢æ¥­")
    print(f"  âœ“ æ–°èè§¸ç™¼ï¼š{len(tw_hotspots)} å€‹ç”¢æ¥­")

    # åˆä½µå»é‡
    final_hotspots = merge_and_deduplicate(us_hotspots, tw_hotspots)

    print(f"\nğŸ”¥ æœ€çµ‚ç†±é»ï¼š{len(final_hotspots)} å€‹ç”¢æ¥­")
    print("=" * 60)

    # è¼¸å‡ºçµæœ
    if not final_hotspots:
        print("\nâš ï¸  ä»Šæ—¥ç„¡æ˜ç¢ºç†±é»ï¼Œå»ºè­°ä¾æ³•äºº TOP50 ç‚ºä¸»")
        return

    for i, hotspot in enumerate(final_hotspots, 1):
        industry_info = industry_chains["industries"][hotspot["industry"]]

        # å¼·åº¦åœ–ç¤º
        if hotspot["strength"] == "strong":
            strength_icon = "ğŸ”´"
            depth = 3
        elif hotspot["strength"] == "medium":
            strength_icon = "ğŸŸ¡"
            depth = 2
        else:
            strength_icon = "âšª"
            depth = 1

        print(f"\n{i}. {strength_icon} {industry_info['name']} ({hotspot['industry']})")
        print(f"   å‚¬åŒ–åŠ‘ï¼š{hotspot['catalyst']}")
        print(f"   å¼·åº¦ï¼š{hotspot['strength']} â†’ å»ºè­°å±•é–‹æ·±åº¦ Tier 0-{depth}")

        # é¡¯ç¤ºæ–°èï¼ˆå¦‚æœæœ‰ï¼‰
        if "news" in hotspot:
            print(f"   ç›¸é—œæ–°èï¼š")
            for news in hotspot["news"]:
                print(f"     - {news}")

    # è¼¸å‡º JSON æ ¼å¼ï¼ˆä¾›ä¸‹ä¸€æ­¥ä½¿ç”¨ï¼‰
    output = {
        "date": date_str,
        "hotspots": final_hotspots,
        "summary": {
            "total": len(final_hotspots),
            "strong": sum(1 for h in final_hotspots if h["strength"] == "strong"),
            "medium": sum(1 for h in final_hotspots if h["strength"] == "medium"),
            "weak": sum(1 for h in final_hotspots if h["strength"] == "weak")
        }
    }

    # ä¿å­˜çµæœ
    output_file = project_root / "data" / date_str / "hotspots.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ çµæœå·²ä¿å­˜ï¼š{output_file}")
    print("\n" + "=" * 60)
    print("âœ… å®Œæˆï¼æ¥ä¸‹ä¾†åŸ·è¡Œ dynamic_industry_expander.py å±•é–‹ç”¢æ¥­éˆ")


if __name__ == "__main__":
    main()
