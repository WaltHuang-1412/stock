import requests
import pandas as pd
import feedparser
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
import yaml
import logging
from urllib.parse import urljoin
import json

class DataFetcher:
    def __init__(self, config_path="config.yaml"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': self.config['scraping']['user_agent']
        })
        
        # è¨­ç½®æ—¥èªŒ
        logging.basicConfig(
            level=getattr(logging, self.config['logging']['level']),
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def fetch_stock_data(self, symbol, market='taiwan'):
        """ç²å–è‚¡ç¥¨åŸºæœ¬æ•¸æ“š"""
        try:
            if market == 'taiwan':
                return self._fetch_taiwan_stock_data(symbol)
            else:
                return self._fetch_us_stock_data(symbol)
        except Exception as e:
            self.logger.error(f"ç²å–è‚¡ç¥¨æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    def _fetch_taiwan_stock_data(self, symbol):
        """ç²å–å°è‚¡æ•¸æ“š"""
        try:
            # æ–¹æ³•1: ä½¿ç”¨è­‰äº¤æ‰€å³æ™‚å ±åƒ¹API
            twse_url = f"https://mis.twse.com.tw/stock/api/getStockInfo.jsp?ex_ch=tse_{symbol}.tw"
            
            response = self.session.get(twse_url, timeout=self.config['scraping']['request_timeout'])
            response.raise_for_status()
            
            data_json = response.json()
            
            if 'msgArray' in data_json and data_json['msgArray']:
                stock_info = data_json['msgArray'][0]
                
                data = {
                    'symbol': symbol,
                    'current_price': stock_info.get('z', 'N/A'),  # æˆäº¤åƒ¹
                    'volume': stock_info.get('v', 'N/A'),         # æˆäº¤é‡
                    'high': stock_info.get('h', 'N/A'),           # æœ€é«˜åƒ¹
                    'low': stock_info.get('l', 'N/A'),            # æœ€ä½åƒ¹
                    'open': stock_info.get('o', 'N/A'),           # é–‹ç›¤åƒ¹
                    'change': stock_info.get('c', 'N/A'),         # æ¼²è·Œ
                    'change_percent': stock_info.get('p', 'N/A'), # æ¼²è·Œå¹…
                    'market': 'taiwan',
                    'timestamp': datetime.now().isoformat(),
                    'source': 'twse_api'
                }
                
                return data
            
            # æ–¹æ³•2: å‚™ç”¨Yahoo Finance (å¦‚æœè­‰äº¤æ‰€APIå¤±æ•—)
            return self._fetch_yahoo_taiwan_stock(symbol)
            
        except Exception as e:
            self.logger.error(f"ç²å–å°è‚¡ {symbol} æ•¸æ“šå¤±æ•—: {e}")
            # å˜—è©¦å‚™ç”¨æ–¹æ³•
            return self._fetch_yahoo_taiwan_stock(symbol)
    
    def _fetch_yahoo_taiwan_stock(self, symbol):
        """å‚™ç”¨æ–¹æ³•: Yahoo Financeå°è‚¡æ•¸æ“š"""
        try:
            url = f"https://tw.finance.yahoo.com/quote/{symbol}.TW"
            
            response = self.session.get(url, timeout=self.config['scraping']['request_timeout'])
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # å˜—è©¦å¤šç¨®å¯èƒ½çš„åƒ¹æ ¼é¸æ“‡å™¨
            price = None
            price_selectors = [
                'span[data-symbol$=".TW"][data-field="regularMarketPrice"]',
                'span.Fw\\(b\\).Fz\\(36px\\)',
                'fin-streamer[data-field="regularMarketPrice"]',
                '.Fw\\(b\\).Fz\\(36px\\).Mt\\(-4px\\)',
            ]
            
            for selector in price_selectors:
                try:
                    element = soup.select_one(selector)
                    if element:
                        price = element.get_text().strip()
                        break
                except:
                    continue
            
            data = {
                'symbol': symbol,
                'current_price': price or 'N/A',
                'market': 'taiwan',
                'timestamp': datetime.now().isoformat(),
                'source': 'yahoo_finance_tw_backup'
            }
            
            return data
            
        except Exception as e:
            self.logger.error(f"Yahooå‚™ç”¨æ–¹æ³•ä¹Ÿå¤±æ•—: {e}")
            return {
                'symbol': symbol,
                'current_price': 'N/A',
                'market': 'taiwan',
                'timestamp': datetime.now().isoformat(),
                'source': 'failed',
                'error': str(e)
            }
    
    def _fetch_us_stock_data(self, symbol):
        """ç²å–ç¾è‚¡æ•¸æ“š"""
        try:
            # Yahoo Finance US API
            url = f"https://finance.yahoo.com/quote/{symbol}"
            
            response = self.session.get(url, timeout=self.config['scraping']['request_timeout'])
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # æå–åƒ¹æ ¼è³‡è¨Š
            price_element = soup.find('fin-streamer', {'data-symbol': symbol, 'data-field': 'regularMarketPrice'})
            price = price_element.get('value') if price_element else 'N/A'
            
            data = {
                'symbol': symbol,
                'current_price': price,
                'market': 'us',
                'timestamp': datetime.now().isoformat(),
                'source': 'yahoo_finance_us'
            }
            
            return data
            
        except Exception as e:
            self.logger.error(f"ç²å–ç¾è‚¡ {symbol} æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    def fetch_institutional_data(self, symbol, market='taiwan'):
        """ç²å–æ³•äººæ•¸æ“š"""
        try:
            if market == 'taiwan':
                return self._fetch_taiwan_institutional_data(symbol)
            else:
                return self._fetch_us_institutional_data(symbol)
        except Exception as e:
            self.logger.error(f"ç²å–æ³•äººæ•¸æ“šå¤±æ•—: {e}")
            return None
    
    def _fetch_taiwan_institutional_data(self, symbol):
        """ç²å–å°è‚¡æ³•äººæ•¸æ“š"""
        try:
            # æ–¹æ³•1: å˜—è©¦è­‰äº¤æ‰€ä¸‰å¤§æ³•äººè²·è³£è¶…API
            today = datetime.now()
            date_str = today.strftime('%Y%m%d')
            
            # å˜—è©¦ç•¶æ—¥æ•¸æ“šï¼Œå¦‚æœæ˜¯å‡æ—¥å‰‡å¾€å‰æ¨
            for i in range(7):  # æœ€å¤šå¾€å‰æ‰¾7å¤©
                check_date = (today - timedelta(days=i)).strftime('%Y%m%d')
                
                url = "https://www.twse.com.tw/rwd/zh/fund/T86"
                params = {
                    'response': 'json',
                    'date': check_date,
                    'selectType': 'ALLBUT0999'
                }
                
                try:
                    response = self.session.get(url, params=params, timeout=self.config['scraping']['request_timeout'])
                    if response.status_code == 200:
                        data = response.json()
                        
                        if 'data' in data and data['data']:
                            for row in data['data']:
                                if len(row) > 0 and row[0] == symbol:
                                    # æˆåŠŸæ‰¾åˆ°æ•¸æ“š
                                    institutional_data = {
                                        'symbol': symbol,
                                        'date': check_date,
                                        'foreign_net': self._safe_convert_to_float(row[4]) if len(row) > 4 else 0,
                                        'investment_trust_net': self._safe_convert_to_float(row[7]) if len(row) > 7 else 0,
                                        'dealer_net': self._safe_convert_to_float(row[10]) if len(row) > 10 else 0,
                                        'total_net': self._safe_convert_to_float(row[13]) if len(row) > 13 else 0,
                                        'source': 'twse',
                                        'timestamp': datetime.now().isoformat()
                                    }
                                    return institutional_data
                except:
                    continue
            
            # å¦‚æœç„¡æ³•ç²å–çœŸå¯¦æ•¸æ“šï¼Œè¿”å› None
            return None
            
        except Exception as e:
            self.logger.error(f"ç²å–å°è‚¡æ³•äººæ•¸æ“šå¤±æ•—: {e}")
            return None
    
    def _safe_convert_to_float(self, value):
        """å®‰å…¨è½‰æ›ç‚ºæµ®é»æ•¸"""
        try:
            if isinstance(value, str):
                # ç§»é™¤åƒåˆ†ä½é€—è™Ÿ
                value = value.replace(',', '')
            return float(value) if value else 0
        except (ValueError, TypeError):
            return 0
    
    
    def _fetch_us_institutional_data(self, symbol):
        """ç²å–ç¾è‚¡æ³•äººæ•¸æ“šï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼‰"""
        # ç¾è‚¡æ³•äººæ•¸æ“šè¼ƒè¤‡é›œï¼Œé€™è£¡å…ˆè¿”å›ç©ºæ•¸æ“š
        return {
            'symbol': symbol,
            'message': 'ç¾è‚¡æ³•äººæ•¸æ“šéœ€è¦æ›´è¤‡é›œçš„å¯¦ç¾',
            'timestamp': datetime.now().isoformat()
        }
    
    def fetch_news_data(self, symbol, market='taiwan'):
        """ç²å–æ–°èæ•¸æ“š"""
        try:
            news_data = []
            
            # é‰…äº¨ç¶²æ–°è
            cnyes_news = self._fetch_cnyes_news(symbol)
            if cnyes_news:
                news_data.extend(cnyes_news)
            
            # Yahooè²¡ç¶“æ–°è
            yahoo_news = self._fetch_yahoo_finance_news(symbol, market)
            if yahoo_news:
                news_data.extend(yahoo_news)
            
            return news_data
            
        except Exception as e:
            self.logger.error(f"ç²å–æ–°èæ•¸æ“šå¤±æ•—: {e}")
            return []
    
    def _fetch_cnyes_news(self, symbol):
        """ç²å–é‰…äº¨ç¶²æ–°è"""
        try:
            # æ–¹æ³•1: å˜—è©¦é‰…äº¨ç¶²å°è‚¡æ–°è
            url = "https://news.cnyes.com/api/v3/news/category/tw_stock"
            
            response = self.session.get(url, timeout=self.config['scraping']['request_timeout'])
            
            if response.status_code == 200:
                data = response.json()
                news_list = []
                
                if 'items' in data and 'data' in data['items']:
                    for article in data['items']['data'][:5]:
                        title = article.get('title', '')
                        # ç°¡å–®é—œéµå­—éæ¿¾
                        if symbol in title or self._is_stock_related(title, symbol):
                            news_item = {
                                'title': title,
                                'summary': article.get('summary', ''),
                                'url': f"https://news.cnyes.com/news/id/{article.get('newsId', '')}",
                                'publish_time': article.get('publishAt', ''),
                                'source': 'cnyes',
                                'symbol': symbol
                            }
                            news_list.append(news_item)
                
                if news_list:
                    return news_list
            
            # ç„¡æ³•ç²å–çœŸå¯¦æ–°èæ•¸æ“š
            return []
            
        except Exception as e:
            self.logger.error(f"ç²å–é‰…äº¨ç¶²æ–°èå¤±æ•—: {e}")
            return []
    
    def _is_stock_related(self, title, symbol):
        """åˆ¤æ–·æ–°èæ˜¯å¦èˆ‡è‚¡ç¥¨ç›¸é—œ"""
        # æ ¹æ“šè‚¡ç¥¨ä»£è™Ÿç²å–å…¬å¸åç¨±
        company_names = {
            '2330': ['å°ç©é›»', 'TSMC'],
            '2317': ['é´»æµ·'],
            '2454': ['è¯ç™¼ç§‘'],
        }
        
        if symbol in company_names:
            return any(name in title for name in company_names[symbol])
        
        return False
    
    
    def _fetch_yahoo_finance_news(self, symbol, market):
        """ç²å–Yahooè²¡ç¶“æ–°è"""
        try:
            if market == 'taiwan':
                url = f"https://tw.finance.yahoo.com/quote/{symbol}.TW/news"
            else:
                url = f"https://finance.yahoo.com/quote/{symbol}/news"
            
            response = self.session.get(url, timeout=self.config['scraping']['request_timeout'])
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # æå–æ–°èæ¨™é¡Œå’Œé€£çµ
            news_items = soup.find_all('a', {'class': lambda x: x and 'Fw(b)' in str(x)})[:5]
            
            news_list = []
            for item in news_items:
                title = item.get_text().strip()
                link = item.get('href', '')
                if link and not link.startswith('http'):
                    link = urljoin(url, link)
                
                news_item = {
                    'title': title,
                    'url': link,
                    'source': 'yahoo_finance',
                    'symbol': symbol,
                    'timestamp': datetime.now().isoformat()
                }
                news_list.append(news_item)
            
            return news_list
            
        except Exception as e:
            self.logger.error(f"ç²å–Yahooè²¡ç¶“æ–°èå¤±æ•—: {e}")
            return []
    
    def fetch_all_data(self, symbol, market='taiwan'):
        """ç²å–æ‰€æœ‰ç›¸é—œæ•¸æ“š"""
        all_data = {
            'symbol': symbol,
            'market': market,
            'fetch_time': datetime.now().isoformat()
        }
        
        # æ·»åŠ å»¶é²é¿å…éå¿«è«‹æ±‚
        delay = self.config['scraping']['delay_between_requests']
        
        # ç²å–è‚¡ç¥¨æ•¸æ“š
        stock_data = self.fetch_stock_data(symbol, market)
        if stock_data:
            all_data['stock_data'] = stock_data
        time.sleep(delay)
        
        # ç²å–æ³•äººæ•¸æ“š
        institutional_data = self.fetch_institutional_data(symbol, market)
        if institutional_data:
            all_data['institutional_data'] = institutional_data
        time.sleep(delay)
        
        # ç²å–æ–°èæ•¸æ“š
        news_data = self.fetch_news_data(symbol, market)
        if news_data:
            all_data['news_data'] = news_data
        time.sleep(delay)
        
        # ç²å–èè³‡èåˆ¸æ•¸æ“š
        margin_data = self.fetch_margin_data(symbol, market)
        if margin_data:
            all_data['margin_data'] = margin_data
        
        return all_data
    
    def fetch_margin_data(self, symbol, market='taiwan'):
        """ç²å–èè³‡èåˆ¸æ•¸æ“š"""
        try:
            if market != 'taiwan':
                return None
                
            # å˜—è©¦ç²å–æœ€è¿‘å¹¾å€‹äº¤æ˜“æ—¥çš„èè³‡èåˆ¸æ•¸æ“š
            today = datetime.now()
            
            for i in range(7):  # æœ€å¤šå¾€å‰æ‰¾7å¤©
                check_date = (today - timedelta(days=i)).strftime('%Y%m%d')
                
                url = "https://www.twse.com.tw/rwd/zh/marginTrading/MI_MARGN"
                params = {
                    'response': 'json',
                    'date': check_date,
                    'selectType': 'ALL'  # æ‰€æœ‰è‚¡ç¥¨è³‡æ–™
                }
                
                try:
                    response = self.session.get(url, params=params, timeout=self.config['scraping']['request_timeout'])
                    if response.status_code == 200:
                        data = response.json()
                        
                        if 'tables' in data and data['tables']:
                            # è§£ætablesçµæ§‹çš„æ•¸æ“š
                            for table in data['tables']:
                                if 'data' in table and table['data']:
                                    for row in table['data']:
                                        if len(row) > 0 and row[0] == symbol:
                                            # æˆåŠŸæ‰¾åˆ°æ•¸æ“š
                                            margin_data = {
                                                'symbol': symbol,
                                                'name': row[1] if len(row) > 1 else '',  # å…¬å¸åç¨±
                                                'date': check_date,
                                                'margin_buy': self._safe_convert_to_float(row[2]) if len(row) > 2 else 0,  # èè³‡è²·é€²
                                                'margin_sell': self._safe_convert_to_float(row[3]) if len(row) > 3 else 0, # èè³‡è³£å‡º  
                                                'margin_net': self._safe_convert_to_float(row[4]) if len(row) > 4 else 0,  # èè³‡æ·¨é¡
                                                'margin_balance': self._safe_convert_to_float(row[5]) if len(row) > 5 else 0, # èè³‡é¤˜é¡
                                                'short_sell': self._safe_convert_to_float(row[8]) if len(row) > 8 else 0,  # èåˆ¸è³£å‡º
                                                'short_buy': self._safe_convert_to_float(row[9]) if len(row) > 9 else 0,   # èåˆ¸è²·é€²
                                                'short_net': self._safe_convert_to_float(row[10]) if len(row) > 10 else 0,  # èåˆ¸æ·¨é¡
                                                'short_balance': self._safe_convert_to_float(row[11]) if len(row) > 11 else 0, # èåˆ¸é¤˜é¡
                                                'source': 'twse_margin',
                                                'timestamp': datetime.now().isoformat()
                                            }
                                            
                                            # è¨ˆç®—ç±Œç¢¼é¢æŒ‡æ¨™
                                            margin_data['margin_ratio'] = self._calculate_margin_ratio(margin_data)
                                            margin_data['short_ratio'] = self._calculate_short_ratio(margin_data)
                                            margin_data['retail_sentiment'] = self._calculate_retail_sentiment(margin_data)
                                            
                                            return margin_data
                except:
                    continue
            
            # ç„¡æ³•ç²å–æ•¸æ“š
            return None
            
        except Exception as e:
            self.logger.error(f"ç²å–èè³‡èåˆ¸æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    def _calculate_margin_ratio(self, margin_data):
        """è¨ˆç®—èè³‡æ¯”ç‡"""
        try:
            margin_balance = margin_data.get('margin_balance', 0)
            if margin_balance > 0:
                return round(margin_balance, 2)
            return 0
        except:
            return 0
    
    def _calculate_short_ratio(self, margin_data):
        """è¨ˆç®—èåˆ¸æ¯”ç‡"""
        try:
            short_balance = margin_data.get('short_balance', 0)
            if short_balance > 0:
                return round(short_balance, 2)
            return 0
        except:
            return 0
    
    def _calculate_retail_sentiment(self, margin_data):
        """è¨ˆç®—æ•£æˆ¶æƒ…ç·’æŒ‡æ¨™"""
        try:
            margin_net = margin_data.get('margin_net', 0)
            short_net = margin_data.get('short_net', 0)
            
            # ç°¡åŒ–çš„æ•£æˆ¶æƒ…ç·’è¨ˆç®—ï¼šèè³‡å¢åŠ è¡¨ç¤ºæ¨‚è§€ï¼Œèåˆ¸å¢åŠ è¡¨ç¤ºæ‚²è§€
            if margin_net > 0 and short_net <= 0:
                return "æ¨‚è§€"
            elif margin_net <= 0 and short_net > 0:
                return "æ‚²è§€" 
            elif margin_net > 0 and short_net > 0:
                return "æ··åˆ"
            else:
                return "ä¸­æ€§"
        except:
            return "ä¸­æ€§"
    
    def fetch_institutional_recommendations(self, top_count=10):
        """å‹•æ…‹ç²å–æ³•äººæŠ•è³‡å‹•å‘æœ€å¼·çš„è‚¡ç¥¨æ¨è–¦"""
        try:
            print("ğŸ“Š æ­£åœ¨å‹•æ…‹æƒæå…¨å¸‚å ´æ³•äººæŠ•è³‡å‹•å‘...")
            
            # ç›´æ¥å¾è­‰äº¤æ‰€APIç²å–æ‰€æœ‰è‚¡ç¥¨çš„æ³•äººè²·è³£è¶…æ•¸æ“š
            today = datetime.now()
            
            # å˜—è©¦æœ€è¿‘å¹¾å€‹äº¤æ˜“æ—¥çš„æ•¸æ“š
            for i in range(7):
                check_date = (today - timedelta(days=i)).strftime('%Y%m%d')
                
                url = "https://www.twse.com.tw/rwd/zh/fund/T86"
                params = {
                    'response': 'json',
                    'date': check_date,
                    'selectType': 'ALLBUT0999'
                }
                
                try:
                    response = self.session.get(url, params=params, timeout=self.config['scraping']['request_timeout'])
                    if response.status_code == 200:
                        data = response.json()
                        
                        if 'data' in data and data['data']:
                            recommendations = []
                            
                            # è™•ç†æ‰€æœ‰è‚¡ç¥¨æ•¸æ“š
                            for row in data['data']:
                                if len(row) >= 14:  # ç¢ºä¿æ•¸æ“šå®Œæ•´
                                    try:
                                        symbol = row[0]
                                        name = row[1]
                                        
                                        # æå–æ³•äººæ•¸æ“š
                                        foreign_net = self._safe_convert_to_float(row[4])
                                        trust_net = self._safe_convert_to_float(row[7]) 
                                        dealer_net = self._safe_convert_to_float(row[10])
                                        total_net = self._safe_convert_to_float(row[13])
                                        
                                        # è¨ˆç®—æ¨è–¦åˆ†æ•¸
                                        score = (foreign_net * 0.6) + (trust_net * 0.3) + (dealer_net * 0.1)
                                        
                                        # é¡å¤–åŠ åˆ†æ¢ä»¶
                                        if foreign_net > 0 and trust_net > 0:
                                            score += 500
                                        elif foreign_net > 1000:
                                            score += 300
                                        elif trust_net > 500:
                                            score += 200
                                        
                                        recommendation = {
                                            'symbol': symbol,
                                            'name': name,
                                            'foreign_net': foreign_net,
                                            'investment_trust_net': trust_net,
                                            'dealer_net': dealer_net,
                                            'total_net': total_net,
                                            'recommendation_score': round(score, 2),
                                            'date': check_date,
                                            'timestamp': datetime.now().isoformat(),
                                            'source': 'twse_dynamic'
                                        }
                                        
                                        recommendations.append(recommendation)
                                        
                                    except Exception as e:
                                        continue
                            
                            # æŒ‰æ¨è–¦åˆ†æ•¸æ’åºï¼Œå–å‰Nå
                            recommendations.sort(key=lambda x: x['recommendation_score'], reverse=True)
                            
                            print(f"âœ… æˆåŠŸæƒæ {len(recommendations)} æ”¯è‚¡ç¥¨ï¼Œæ‰¾å‡ºæ³•äººæœ€æ„›å‰{top_count}å")
                            return recommendations[:top_count]
                
                except Exception as e:
                    continue
            
            # å¦‚æœéƒ½ç„¡æ³•ç²å–ï¼Œè¿”å›ç©ºæ•¸æ“š
            print("âŒ ç„¡æ³•ç²å–å‹•æ…‹æ³•äººæ•¸æ“š")
            return []
            
        except Exception as e:
            self.logger.error(f"å‹•æ…‹ç²å–æ³•äººæ¨è–¦å¤±æ•—: {e}")
            return []
    
    def _calculate_recommendation_score(self, institutional_data):
        """è¨ˆç®—æ¨è–¦åˆ†æ•¸"""
        try:
            foreign_net = float(institutional_data.get('foreign_net', 0))
            trust_net = float(institutional_data.get('investment_trust_net', 0))
            dealer_net = float(institutional_data.get('dealer_net', 0))
            
            # æ¬Šé‡è¨­å®š: å¤–è³‡>æŠ•ä¿¡>è‡ªç‡Ÿå•†
            score = (foreign_net * 0.6) + (trust_net * 0.3) + (dealer_net * 0.1)
            
            # é¡å¤–åŠ åˆ†é …ç›®
            if foreign_net > 0 and trust_net > 0:  # å¤–è³‡æŠ•ä¿¡é›™è²·è¶…
                score += 500
            elif foreign_net > 1000:  # å¤–è³‡å¤§è²·è¶…
                score += 300
            elif trust_net > 500:  # æŠ•ä¿¡å¤§è²·è¶…
                score += 200
            
            return round(score, 2)
            
        except (ValueError, TypeError):
            return 0
    

def test_data_fetcher():
    """æ¸¬è©¦æ•¸æ“šç²å–å™¨"""
    fetcher = DataFetcher()
    
    # æ¸¬è©¦å°è‚¡
    print("æ¸¬è©¦å°ç©é›»æ•¸æ“šç²å–:")
    data = fetcher.fetch_all_data('2330', 'taiwan')
    print(json.dumps(data, ensure_ascii=False, indent=2))
    
    print("\n" + "="*50 + "\n")
    
    # æ¸¬è©¦ç¾è‚¡
    print("æ¸¬è©¦è˜‹æœè‚¡ç¥¨æ•¸æ“šç²å–:")
    data = fetcher.fetch_all_data('AAPL', 'us')
    print(json.dumps(data, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    test_data_fetcher()